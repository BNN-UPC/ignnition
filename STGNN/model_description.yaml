# Definition of the entities
entities:
- name: sensor
  state_dimensions: 1
  initial_state:
  - type: neural_network
    input: [Q_value]
    nn_name: feed_forward
    output_name: sensor

# Definition of the message passing phase  

spatial_message_passing: #la fase espaial, graph canvo i 
  num_iterations: N
  stages:
    - stage_message_passings:
      - destination_entity: array
        source_entities:
        - name: [sensor]
          message:
            - type: neural_network
              nn_name: feed_Dorward
              input: [Q_value]
        aggregation:
          -type: sum
        update:
          type: neural_network
          nn_name: update_function

temporal_message_passing:
  num_iterations: 1
  stages:
    - stage_message_passings:
      - destination_enitity: sensor
        source_entities:
          - name: array
            update:
              type: neural_network
              nn_name: GRU
 
transform:
- type: neural_network
  input: array
  nn_name: transformer_block
  output_label: [Q_val]

# Definition of the readout
readout:
- type: neural_network
  input: [Q_val]
  nn_name: readout_model
  output_label: [$Q_val]

neural_networks:
  - nn_name: readout_model
  nn_architecture:
  - type_layer: Dense
    units: 64
    activation: relu
  - type_layer: Dense
    units: 32
    activation: relu
  - type_layer: Dense
    units: 1
    activation: None

- nn_name: feed_forward
  nn_architecture:
    - type_layer: batch_normalization
    - loop: 64
      - type_layer: Dense
        units: 64
        activation: relu
      - type_layer: Dropout
        rate: 0.2
    - type_layer: Dense
      units: 64
      activation: relu

- nn_name: transformer_block
  nn_architecture:
    - type_layer: MultiHeadAttention
      num_heads: 4
      key_dim: 64
    - type_layer: Dropout
      rate: 0.2
    - type_layer: LayerNormalization
      epsilon: 1e-6
    - type_layer: Dense
      units: 64
      activation: relu
    - type_layer: Dense
      units: 64
    - type_layer: Dropout
      rate: 0.2
    - type_layer: LayerNormalization
      epsilon: 1e-6

- nn_name: GRU
  nn_architecture:
    - type_layer: GRUcell
  
- nn_name: update_function
  nn_architecture:
    - type_layer: GRU
