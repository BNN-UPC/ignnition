# Definition of the entities
entities:
- name: sensor
  state_dimensions: 1
  initial_state:
  - type: build_state
    input: [$Q_val]

- name: array
  state_dimensions: *
  initial_state:
  - type: empty

# Definition of the message passing phase  

preparation:
  - preprocessing:
    - destination_entity: array
    source_entities:
      - name: sensor
        func:
          type: neural_network
          nn_name: preprocessing
#// no esta ni de collons fet b√©
st_loop:
  num_iterations: N
  prep:
    - preprocessing:
      - destination_entity: array
      source_entities:
        - name: sensor
          func:
            type: neural_network
            nn_name: preprocessing
  spatial:
    - GCN:
      - destination_entity: sensor
      source_enties: sensor
        - name: sensor
          func:
            type: neural_network
            nn_name: GCN
  temporal:
    - GRU:
      - destination_entity: array
      source_enties: 
        - name: sensor
          name: array
          func:
            type: neural_network
            nn_name: GRU

transform:
- type: neural_network
  input: array
  nn_name: transformer_block
  output_label: [Q_val]

# Definition of the readout
readout:
- type: neural_network
  input: [Q_val]
  nn_name: readout_model
  output_label: [$Q_val]

neural_networks:
  - nn_name: readout_model
  nn_architecture:
  - type_layer: Dense
    units: 64
    activation: relu
  - type_layer: Dense
    units: 32
    activation: relu
  - type_layer: Dense
    units: 1
    activation: None

- nn_name: preprocessing
  nn_architecture:
    - type_layer: batch_normalization
    - loop: 64
      - type_layer: Dense
        units: 64
        activation: relu
      - type_layer: Dropout
        rate: 0.2
    - type_layer: Dense
      units: 64
      activation: relu

- nn_name: transformer_block
  nn_architecture:
    - type_layer: MultiHeadAttention
      num_heads: 4
      key_dim: 64
    - type_layer: Dropout
      rate: 0.2
    - type_layer: LayerNormalization
      epsilon: 1e-6
    - type_layer: Dense
      units: 64
      activation: relu
    - type_layer: Dense
      units: 64
    - type_layer: Dropout
      rate: 0.2
    - type_layer: LayerNormalization
      epsilon: 1e-6

-nn_name: GCN
  nn_architecture:
    - type:layer: GCN
      units: 64

-nn_name: GRU
  nn_architecture:
    - type_layer: GRUcell
  